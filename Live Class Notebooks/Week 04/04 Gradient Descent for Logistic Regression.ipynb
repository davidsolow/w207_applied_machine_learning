{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"imcNmFXhPdCh"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-01 17:50:54.322451: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-01 17:50:54.322474: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-01 17:50:54.362772: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-01 17:50:54.447745: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-01 17:50:55.373456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# Import our standard libraries.\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns  # for nicer plots\n","sns.set(style='darkgrid')  # default style\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"VloE32t7dkU1"},"source":["## Logistic Regression\n","\n","Suppose we have a dataset with 2 datapoints, $x^{(0)}$ and $x^{(1)}$, each with 3 features (and a dummy 1 for learning the bias). Now our target labels are binary (0 or 1)."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8bcduWsAbCRl"},"outputs":[],"source":["# Here are our inputs.\n","X = np.array([[1, 3, -2, 0],\n","              [1, 1, 0, 1]])\n","Y = np.array([0, 1])"]},{"cell_type":"markdown","metadata":{"id":"_tdGfEoDovBm"},"source":["Let's write out our model function:\n","\n","\\begin{align}\n","h_W(x) = \\phi(w_0x_0 + w_1x_1 + w_2x_2 + w_3x_3) = \\phi(xW^T) = \\frac{1}{1+e^{(-xW^T)}}\n","\\end{align}\n","\n","We can get all predictions with this matrix product:\n","\n","\\begin{align}\n","\\hat{Y} = h_W(X) = \\phi(XW^T) =\n","\\phi\\begin{pmatrix}\n","x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n","x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n","\\vdots & \\vdots & \\vdots & \\vdots \\\\\n","x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","w_0 \\\\\n","w_1 \\\\\n","w_2 \\\\\n","w_3 \\\\\n","\\end{pmatrix}\n","\\end{align}\n","\n","First let's write the sigmoid (logistic) function $\\phi$."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Hpah13BcCVXo"},"outputs":[],"source":["def sigmoid(z):\n","  return 1 / (1 + np.exp(-z))"]},{"cell_type":"markdown","metadata":{"id":"KLh6VWUfGm7_"},"source":["Now, given some initial parameter values (below), compute the model's initial predictions."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pGg1Ll4I4jR6"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.88079708 0.95257413]\n"]}],"source":["# Initial parameter values.\n","W = [1, 1, 1, 1]\n","\n","# Compute predictions.\n","preds = sigmoid(np.dot(X, W))\n","print(preds)"]},{"cell_type":"markdown","metadata":{"id":"ZIbpXB4ZHPvO"},"source":["We're not going to use MSE for logistic regression. Instead, we'll use the *logistic loss*, also called *binary cross-entropy* (more on that name later):\n","\n","\\begin{align}\n","LogLoss = \\frac{1}{m} \\sum_i -y_i\\log(\\hat{y_i}) - (1-y_i)\\log(1-\\hat{y_i})\n","\\end{align}\n","\n","Despite this new loss function, it turns out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n","\n","\\begin{align}\n","\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)X\n","\\end{align}\n","\n","Let's write the code for a single gradient descent step:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Zl_Nu_wB8ar4"},"outputs":[{"name":"stdout","output_type":"stream","text":["predictions: [0.88079708 0.95257413]\n","loss: 1.0877576813083567\n","gradient: [ 0.4166856   1.29748268 -0.88079708 -0.02371294]\n","weights: [0.95833144 0.87025173 1.08807971 1.00237129]\n"]}],"source":["# Run gradient descent\n","m, n = X.shape  # m = number of examples; n = number of features (including bias)\n","learning_rate = 0.1\n","\n","preds = sigmoid(np.dot(X, W))\n","loss = (-Y * np.log(preds) - (1 - Y) * np.log(1 - preds)).mean()\n","gradient = np.dot((preds - Y), X) / m\n","W = W - learning_rate * gradient\n","\n","print('predictions:', preds)\n","print('loss:', loss)\n","print('gradient:', gradient)\n","print('weights:', W)"]},{"cell_type":"markdown","metadata":{"id":"BMsSJ-ZD_12e"},"source":["## Now with TensorFlow/Keras"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jisaFtGY__KL"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-01 17:52:06.522512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.715096: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.715285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.716457: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.716618: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.716761: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.795912: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.796094: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.796377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-01 17:52:06.796547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9588 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n"]}],"source":["tf.keras.backend.clear_session()\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(\n","    units=1,                     # output dim\n","    input_shape=[4],             # input dim\n","    use_bias=False,              # we included the bias in X\n","    activation='sigmoid',        # apply a sigmoid to the output\n","    kernel_initializer=tf.ones_initializer,  # initialize params to 1\n","))\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)\n","model.compile(loss='binary_crossentropy', optimizer=optimizer)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"3PQ-RDwXCKVt"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 276ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-01 17:52:11.027125: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"]},{"name":"stdout","output_type":"stream","text":["predictions: [[0.880797   0.95257413]]\n","loss: 1.0877577066421509\n","W: [[0.95833147 0.8702517  1.0880797  1.0023713 ]]\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-01 17:52:11.675875: I external/local_xla/xla/service/service.cc:168] XLA service 0x7b87d00da270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2024-02-01 17:52:11.675892: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n","2024-02-01 17:52:11.690763: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1706827931.732590   17682 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]}],"source":["# As above, get predictions for the current model first.\n","preds = model.predict(X)\n","\n","# Do a single gradient update.\n","history = model.fit(\n","  x = X,\n","  y = Y,\n","  epochs=1,\n","  batch_size=2,\n","  verbose=0)\n","\n","# Show the loss (before the update) and the new weights.\n","loss = history.history['loss'][0]\n","weights = model.layers[0].get_weights()[0].T\n","print('predictions:', preds.T)\n","print('loss:', loss)\n","print('W:', weights)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPYfdglyDDTfD4jgFZaisB0","name":"02 Gradient Descent for Logistic Regression.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
