{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"imcNmFXhPdCh"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-08 19:01:57.157274: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-08 19:01:57.157299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-08 19:01:57.195328: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-08 19:01:57.275653: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-08 19:01:58.254137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-02-08 19:01:59.083866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.285676: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.286046: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"]},{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# Import our standard libraries.\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","sns.set(style='darkgrid')\n","import tensorflow as tf\n","np.set_printoptions(precision=3, suppress=True)\n","from sklearn import datasets\n","\n","## Importing all required libraries - in this case using GPU, verify GPU connection below:\n","tf.config.list_physical_devices('GPU')"]},{"cell_type":"markdown","metadata":{"id":"P4mROCY5wAX4"},"source":["## Iris Classification\n","\n","We will train a classifier to predict 3 iris varieties from 4 features of each flower. Note: we are not doing image classification here!\n","\n","![An image](flowers.png)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"37XEUjK4ulzp"},"outputs":[{"name":"stdout","output_type":"stream","text":["X shape: (150, 4)\n","Y shape: (150,)\n","feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n","class names: ['setosa' 'versicolor' 'virginica']\n","First example: [5.1 3.5 1.4 0.2] 0\n"]},{"data":{"text/plain":["'\\nThis cell loads the data from sci-kit learn datasets and returns basic information about its structure.\\n'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Load the data\n","iris = datasets.load_iris()\n","X = iris.data\n","Y = iris.target\n","feature_names = iris.feature_names\n","class_names = iris.target_names\n","\n","print('X shape:', X.shape)\n","print('Y shape:', Y.shape)\n","print('feature names:', feature_names)\n","print('class names:', class_names)\n","print('First example:', X[0], Y[0])\n","\n","\"\"\"\n","This cell loads the data from sci-kit learn datasets and returns basic information about its structure.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"O3GC13Sf219q"},"source":["## Data Processing\n","\n","* Shuffle\n","* Split into train/test\n","* Apply mean and variance normalization"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-sa_lrwU1oiT"},"outputs":[{"data":{"text/plain":["'\\nThis cell shuffles all data by randomly coming up with a parallel index\\nIt then parces the data into 2/3 training and 1/3 test\\nIt then applies mean / variance normalization to make the mean of all features 0 and std 1\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["np.random.seed(0)\n","shuffled_indices = np.random.permutation(range(len(Y)))\n","X = X[shuffled_indices]\n","Y = Y[shuffled_indices]\n","\n","X_train = X[0:100]\n","Y_train = Y[0:100]\n","X_test = X[100:150]\n","Y_test = Y[100:150]\n","\n","X_train_means = np.mean(X_train, axis=0)\n","X_train_stds = np.std(X_train, axis=0)\n","X_train = (X_train - X_train_means) / X_train_stds\n","X_test = (X_test - X_train_means) / X_train_stds\n","\n","\"\"\"\n","This cell shuffles all data by randomly coming up with a parallel index\n","It then parces the data into 2/3 training and 1/3 test\n","It then applies mean / variance normalization to make the mean of all features 0 and std 1\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"4jIgCYbiVAz3"},"source":["## Sparse vs Dense Representation"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"8bcduWsAbCRl"},"outputs":[{"name":"stdout","output_type":"stream","text":["(100, 3)\n","[[0. 0. 1.]\n"," [0. 1. 0.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]\n"," [1. 0. 0.]\n"," [0. 0. 1.]]\n"]},{"data":{"text/plain":["\"\\nThis cell converts Y training data to a dense form using Keras' to_categorical method\\n\""]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Convert Y from sparse to dense if needed\n","# one-hot [0, 0, 1] -> 2\n","# one-hot [0, 1, 0] -> 1\n","# one-hot [1, 0, 0] -> 0\n","\n","Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n","print(Y_train_dense.shape)\n","print(Y_train_dense[:6])\n","\n","\"\"\"\n","This cell converts Y training data to a dense form using Keras' to_categorical method\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"FS7LIrIlVd2E"},"source":["## Softmax Regression Functional Form"]},{"cell_type":"markdown","metadata":{"id":"_tdGfEoDovBm"},"source":["We will use *softmax regression*, which extends *logistic regression* to the multiclass setting. Our model will make predictions for input examples $X$ by:\n","\n","\\begin{align}\n","\\hat{Y} = h_W(X) = \\phi(XW^T) =\n","\\phi\\begin{pmatrix}\n","x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n","x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n","\\vdots & \\vdots & \\vdots & \\vdots \\\\\n","x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n","\\end{pmatrix}\n","\\begin{pmatrix}\n","w_{0,0} & w_{1,0} & w_{2,0} \\\\\n","w_{0,1} & w_{1,1} & w_{2,1} \\\\\n","w_{0,2} & w_{1,2} & w_{2,2} \\\\\n","w_{0,3} & w_{1,3} & w_{2,3} \\\\\n","\\end{pmatrix}\n","\\end{align}\n","\n","A few notes about this computation:\n","\n","* Our X has shape (100 x 4): 100 examples and 4 features\n","* Our W has shape (3 x 4): 3 classes and 4 features. The indices above are reversed because we've taken the transpose of W: the first column of $W^T$ contains the weights for the first class.\n","* The result will have shape (100 x 3): 3 probabilities corresponding to the 3 classes for each of the 100 examples.\n","* $\\phi$ is the softmax function: $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$. It is applied to the rows of $XW^T$.\n","\n","More detailed background [here](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)."]},{"cell_type":"markdown","metadata":{},"source":["### Notes\n","Softmax applies a function $\\phi$, defined as $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$, to our features and weights $XW^T$. This results in a probability prediction for each class for each sample."]},{"cell_type":"markdown","metadata":{"id":"nAoIx-nkXhD-"},"source":["## Softmax Normalization"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Hpah13BcCVXo"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.09  0.245 0.665]\n"," [0.016 0.117 0.867]]\n"]},{"data":{"text/plain":["'\\nThis cell implements the softmax function. First, all values are raised to the power of e.\\nThen, these raised values are summed. This is the denominator of the softmax function.\\nFinally, the numerator (our values) are divided by this denominator iteratively\\nA vectorized method using the transpose of each vector is also implemented\\n'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Remember the sigmoid function.\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","# Our softmax function will normalize over the rows of the input matrix.\n","def softmax(z):\n","  \"\"\"z has shape (m, n): examples, classes\"\"\"\n","  (m, n) = z.shape\n","\n","  # First exponentiate each value\n","  exps = np.exp(z)\n","\n","  # Get the sum of each row and normalize\n","  row_sums = np.sum(exps, axis=1)\n","  for i in range(m):\n","    exps[i,:] /= row_sums[i]\n","  \n","  # Fancy/tricky way to do row-wise sums in numpy:\n","  # return np.divide(exps.T, np.sum(exps, axis=1)).T\n","\n","  return exps\n","\n","# Try an example.\n","v = np.array([[1,2,3],\n","              [0,2,4]])\n","print(softmax(v))\n","\n","\"\"\"\n","This cell implements the softmax function. First, all values are raised to the power of e.\n","Then, these raised values are summed. This is the denominator of the softmax function.\n","Finally, the numerator (our values) are divided by this denominator iteratively\n","A vectorized method using the transpose of each vector is also implemented\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"KLh6VWUfGm7_"},"source":["## Making Predictions\n","\n","Now, given some initial parameter values (below), compute the model's initial predictions."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"pGg1Ll4I4jR6"},"outputs":[{"name":"stdout","output_type":"stream","text":["predictions:\n"," [[0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]]\n","predictions:\n"," [0 0 0 0 0 0]\n","true labels:\n"," [2 1 0 2 0 2]\n"]},{"data":{"text/plain":["'\\nThis sell initiates weights as all equal to 1 and then makes a prediction using the softmax funciton.\\nThe predictions are all 0 given that these weights are meaningless\\n'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Initial parameter values.\n","# W = np.random.uniform(size=(3,4))\n","W = np.ones((3,4))\n","\n","# Compute predictions.\n","preds = softmax(np.dot(X_train, W.T))\n","print('predictions:\\n', preds[:6])\n","print('predictions:\\n', np.argmax(preds, axis=1)[:6])\n","print('true labels:\\n', Y_train[:6])\n","\n","\"\"\"\n","This sell initiates weights as all equal to 1 and then makes a prediction using the softmax funciton.\n","The predictions are all 0 given that these weights are meaningless\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"ZIbpXB4ZHPvO"},"source":["## Cross-Entropy Loss\n","\n","We'll use the general form of *cross-entropy* loss:\n","\n","\\begin{align}\n","CrossEntropyLoss = \\frac{1}{m} \\sum_i \\sum_j -y_j\\log(\\hat{y_j})\n","\\end{align}\n","\n","In this formula:\n","\n","* $j$ indexes the classes (in our case [0,1,2]) and each $y$ has a dense representation like [0,0,1] which indicates class 2.\n","* *i* indexes over training examples, so we're computing an average loss (as usual)."]},{"cell_type":"markdown","metadata":{},"source":["## Notes\n","Cross entropy will be used as the loss function for gradient descent. It compares two distributions, in this case the distribution of probabilities of our class predictions compared to the actual classes, and penalizes probabilities that are far away from the real class values."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lWxpr2OogN70"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0986122886681093\n"]},{"data":{"text/plain":["'\\nThis cell implements cross entropy loss. Dense labels gathered, and then cross entropy is calculated.\\nLoss is then aclculated by taking the average of the cross entropy values.\\n'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["def ce_loss(preds, Y):\n","    \"\"\"\n","    preds are (m,n) m= number of examples, n = number of classes\n","    Y is (m,) -- array of sparse labels\n","    preds[0] = [.1, .1, .8] Y[0] = 2 Y_dense[0] = [0, 0, 1]\n","    \"\"\"\n","    # Get the number of examples\n","    m = Y.shape[0]\n","    \n","    # Compute the first sum, the cross-entropy for each example, using\n","    # the rows of the predictions and corresponding labels.\n","    # Note that we need the dense (one-hot) labels.\n","    Y_dense = tf.keras.utils.to_categorical(Y)\n","    # [.1, .1, .8] [0, 0, 1] -> [0, 0, -1*log(.8)] -> -1*log(.8)\n","    cross_entropy_values = - np.sum(Y_dense * np.log(preds), axis=1)\n","\n","    # Here's a more efficient but tricky way to do this:\n","    # cross_entropy_values = -np.log(preds[range(m), Y])\n","\n","    # Sum the per-example cross-entropy values.\n","    loss = np.sum(cross_entropy_values) / m\n","\n","    return loss\n","\n","#print(ce_loss(np.array([.1, .1, .8]), np.array([2])))\n","print(ce_loss(preds, Y_train))\n","\n","\"\"\"\n","This cell implements cross entropy loss. Dense labels gathered, and then cross entropy is calculated.\n","Loss is then aclculated by taking the average of the cross entropy values.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"BaRg8b1F93w9"},"source":["## Computing the Gradient\n","\n","Again, it will turn out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n","\n","\\begin{align}\n","\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)^TX\n","\\end{align}\n","\n","Remember that our parameters $W$ are represented by a matrix of shape (3 x 4): 3 classes and 4 features. The gradient will include a partial derivative for every parameter, and is an average over gradients computed on each training example.\n","\n","Let's review the matrix shapes:\n","\n","* $h_W(X)$ is (100 x 3): 3 probabilities for each example.\n","* $Y$ is (100 x 3): this is the dense (one-hot) version of the labels, matching the shape of the predictions.\n","* $X$ is (100 x 4): 4 features for each example.\n","* The resulting product is (3 x 100)(100 x 4), giving a (3 x 4) output, which matches the shape of our parameters $W$.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0-j0soKK2qfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["gradient:\n"," [[ 0.337 -0.28   0.431  0.411]\n"," [-0.042  0.191 -0.089 -0.046]\n"," [-0.295  0.09  -0.342 -0.365]]\n"]},{"data":{"text/plain":["'\\nThis cell shows an example of calculating the gradient by taking the dot product of\\nthe differences tranposed and the training data, and then dividing that by the number of samples\\n'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# y' = [.1, .2, .7]  y = [0, 0, 1]  diff = y' - y = [.1, .2, -.3]\n","# d1 = [.1, .2, -.3]  x1 = [1, 2, 3, 4]\n","# (3 x 100) (100 x 4) -> (3 x 4)\n","# [ [ .1*1,  .1*2,  .1*3,  .1*4 ]\n","#   [ .2*1,  .2*2,  .2*3,  .2*4 ]\n","#   [-.3*1, -.3*2, -.3*3, -.3*4 ]\n","# ]\n","#\n","# We need the dense version of Y here\n","m = Y_train.shape[0]\n","Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n","diff = preds - Y_train_dense\n","gradient = np.dot(diff.T, X_train) / m\n","print('gradient:\\n', gradient)\n","\n","\"\"\"\n","This cell shows an example of calculating the gradient by taking the dot product of\n","the differences tranposed and the training data, and then dividing that by the number of samples\n","\"\"\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ExL4G-pMAXvV"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0.333]\n"," [ 0.333]\n"," [-0.667]]\n","[[-0.017 -0.543  0.76   1.567]]\n","gradient:\n"," [[-0.006 -0.181  0.253  0.522]\n"," [-0.006 -0.181  0.253  0.522]\n"," [ 0.011  0.362 -0.507 -1.045]]\n"]},{"data":{"text/plain":["'\\nThis cell shows examples of the gradient calculation for the first sample\\n'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Simplify and just compute the gradient for the first training example.\n","print(diff[0:1].T)\n","print(X_train[0:1])\n","print('gradient:\\n', np.dot(diff[0:1].T, X_train[0:1]))\n","\n","\"\"\"\n","This cell shows examples of the gradient calculation for the first sample\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"VZDyrbc42rcF"},"source":["## Running Gradient Descent\n","\n","Let's put together the code for a single gradient descent step:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Zl_Nu_wB8ar4"},"outputs":[{"name":"stdout","output_type":"stream","text":["labels:\n"," [2 1 0 2 0 2]\n","predictions:\n"," [[0.025 0.201 0.774]\n"," [0.084 0.673 0.243]\n"," [0.99  0.006 0.003]\n"," [0.007 0.154 0.838]\n"," [0.962 0.032 0.006]\n"," [0.014 0.081 0.905]]\n","loss: 0.43657251861677077\n","gradient:\n"," [[ 0.012 -0.026  0.026  0.023]\n"," [-0.01   0.026 -0.007  0.01 ]\n"," [-0.001 -0.    -0.018 -0.033]]\n","weights:\n"," [[0.539 1.556 0.295 0.347]\n"," [1.08  0.492 1.132 0.922]\n"," [1.381 0.951 1.573 1.731]]\n"]},{"data":{"text/plain":["'\\nThis cell implements gradient descent for 1000 epochs and a learning rate of 0.01 interatively.\\n'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Run gradient descent\n","m, n = X.shape # m = number of examples; n = number of features(including bias)\n","learning_rate = 0.01\n","\n","for _ in range(1000):\n","    preds = softmax(np.dot(X_train, W.T))\n","    loss = ce_loss(preds, Y_train)\n","    gradient = np.dot((preds - tf.keras.utils.to_categorical(Y_train)).T, X_train) / m\n","    W = W - learning_rate * gradient\n","\n","print('labels:\\n', Y_train[:6])\n","print('predictions:\\n', preds[:6])\n","print('loss:', loss)\n","print('gradient:\\n', gradient)\n","print('weights:\\n', W)\n","\n","\"\"\"\n","This cell implements gradient descent for 1000 epochs and a learning rate of 0.01 interatively.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"8q72Tu_n_LlO"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"tj3z7t6-_PZ4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.84\n"]},{"data":{"text/plain":["'\\nThis cell takes the weights from gradient descent and applies them to the softmax function to make\\npredictions on test data. It returns an accuracy score.\\n'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Make predictions on the test data\n","test_preds = softmax(np.dot(X_test, W.T))\n","test_pred_labels = np.argmax(test_preds, axis=1)\n","print('Accuracy:', np.mean(test_pred_labels == Y_test))\n","\n","\"\"\"\n","This cell takes the weights from gradient descent and applies them to the softmax function to make\n","predictions on test data. It returns an accuracy score.\n","\"\"\""]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xcq8zqKDALmC"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-08 19:01:59.580003: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.580212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.580367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.661436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.661621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.661780: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n","2024-02-08 19:01:59.661899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9886 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6\n","2024-02-08 19:01:59.923102: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"]},{"data":{"text/plain":["'\\nThis cell plots a confusion matrix of the previous example.\\n'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["cf = tf.math.confusion_matrix(Y_test, test_pred_labels)\n","ax = sns.heatmap(cf, annot=True, fmt='.3g', cmap='Blues',\n","                 xticklabels=class_names, yticklabels=class_names, cbar=False)\n","ax.set(xlabel='Predicted Label', ylabel='True Label')\n","plt.show\n","\n","\"\"\"\n","This cell plots a confusion matrix of the previous example.\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"BMsSJ-ZD_12e"},"source":["## Now with TensorFlow/Keras"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"jisaFtGY__KL"},"outputs":[{"data":{"text/plain":["'\\nThis cell sets up our one layer keras model for multiclass logisitic regression.\\n'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.backend.clear_session()\n","model = tf.keras.Sequential()\n","model.add(tf.keras.layers.Dense(\n","    units=3,                    # output dim\n","    input_shape=[4],            # input dim\n","    use_bias=False,             # we included the bias in X\n","    activation='softmax',      # apply a sigmoid to the output\n","    kernel_initializer=tf.ones_initializer, # initialize params to 1\n","))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n","\n","\"\"\"\n","This cell sets up our one layer keras model for multiclass logisitic regression.\n","\"\"\""]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3PQ-RDwXCKVt"},"outputs":[{"name":"stdout","output_type":"stream","text":["5/5 [==============================] - 0s 948us/step\n"]},{"name":"stderr","output_type":"stream","text":["2024-02-08 19:02:00.622802: I external/local_xla/xla/service/service.cc:168] XLA service 0x76a2f591b560 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2024-02-08 19:02:00.622818: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n","2024-02-08 19:02:00.630555: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-02-08 19:02:00.649546: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1707436920.713275    6778 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["predictions:\n"," [[0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]\n"," [0.333 0.333 0.333]]\n","loss: 0.990375280380249\n","W:\n"," [[ 0.257  2.901 -0.779 -0.707]\n"," [ 1.626 -0.311  2.092  0.157]\n"," [ 1.228  0.609  2.049  2.974]]\n"]},{"data":{"text/plain":["'\\nThis cell fits the model for 100 epochs and a batch size of 10.\\nIt then prints out the predictions for the first 6 samples, the loss, and the final weights.\\n'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# As above, get predictions for the current model first.\n","preds = model.predict(X)\n","\n","# Do a single gradient update.\n","history = model.fit(\n","    x = X_train,\n","    y = Y_train,\n","    epochs=100,\n","    batch_size=10,\n","    verbose=0\n",")\n","\n","# Show the loss (before the update) and the new weights.\n","loss = history.history['loss'][0]\n","weights = model.layers[0].get_weights()[0].T\n","print('predictions:\\n', preds[:6])\n","print('loss:', loss)\n","print('W:\\n', weights)\n","\n","\"\"\"\n","This cell fits the model for 100 epochs and a batch size of 10.\n","It then prints out the predictions for the first 6 samples, the loss, and the final weights.\n","\"\"\""]},{"cell_type":"code","execution_count":15,"metadata":{"id":"QAmb6PMCTVET"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.990375280380249, 0.7967755794525146, 0.6771520972251892, 0.5968527793884277, 0.5492150783538818, 0.5157124996185303, 0.493833988904953, 0.4753832519054413, 0.4632093906402588, 0.45182713866233826, 0.4425351619720459, 0.4349922239780426, 0.42973342537879944, 0.4224408268928528, 0.41705211997032166, 0.41252875328063965, 0.40790805220603943, 0.4042285084724426, 0.40097999572753906, 0.3972621560096741, 0.394033819437027, 0.39123666286468506, 0.3888702392578125, 0.38593590259552, 0.38395756483078003, 0.382277250289917, 0.37955406308174133, 0.377309650182724, 0.37643375992774963, 0.37366122007369995, 0.3739987313747406, 0.3705388009548187, 0.36934810876846313, 0.3678604066371918, 0.367064505815506, 0.3652578592300415, 0.36418837308883667, 0.3628968298435211, 0.36233651638031006, 0.36071503162384033, 0.3599056899547577, 0.3591265380382538, 0.3583102524280548, 0.3577701449394226, 0.35645174980163574, 0.35584911704063416, 0.3553796708583832, 0.3546454608440399, 0.35383617877960205, 0.35330161452293396, 0.35251906514167786, 0.35162752866744995, 0.35109007358551025, 0.3503322899341583, 0.35004696249961853, 0.3492993414402008, 0.34937232732772827, 0.34928250312805176, 0.3479067087173462, 0.3477368950843811, 0.3472888469696045, 0.3465058505535126, 0.3460601568222046, 0.3459479510784149, 0.3452428877353668, 0.34518563747406006, 0.3450395464897156, 0.34444552659988403, 0.34357792139053345, 0.3440271317958832, 0.34370651841163635, 0.3428831100463867, 0.34268805384635925, 0.3423749506473541, 0.3420043885707855, 0.3419052064418793, 0.3417060971260071, 0.34079933166503906, 0.3410569429397583, 0.3409384787082672, 0.3401106595993042, 0.33996880054473877, 0.33974114060401917, 0.3398764729499817, 0.3395944833755493, 0.3390805423259735, 0.33894237875938416, 0.33855488896369934, 0.33836886286735535, 0.33834874629974365, 0.33783432841300964, 0.3376888930797577, 0.3373958170413971, 0.3377053141593933, 0.3369812071323395, 0.3369789123535156, 0.33671921491622925, 0.3362470269203186, 0.3360917270183563, 0.3365156650543213]\n"]}],"source":["print(history.history['loss'])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"DuKK7l4fTktl"},"outputs":[{"name":"stdout","output_type":"stream","text":["2/2 [==============================] - 0s 1ms/step\n"]},{"name":"stdout","output_type":"stream","text":["0.9\n","2/2 [==============================] - 0s 3ms/step - loss: 0.2554\n"]},{"data":{"text/plain":["0.25537192821502686"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["test_preds = model.predict(X_test)\n","test_preds_labels = np.argmax(test_preds, axis=1)\n","accuracy = np.mean(test_preds_labels == Y_test)\n","print(accuracy)\n","model.evaluate(x=X_test, y=Y_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOF/SzfGqGLnE58b8QnQuUU","name":"03 Multiclass Logistic Regression.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
